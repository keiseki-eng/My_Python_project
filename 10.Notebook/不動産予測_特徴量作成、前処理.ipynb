{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from seaborn) (2.3.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from seaborn) (2.3.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from seaborn) (3.10.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/keiseki/My_Python_project/venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages', '/home/keiseki/My_Python_project/src']\n"
          ]
        }
      ],
      "source": [
        "import sys; print(sys.path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A8CzKrBbb7O",
        "outputId": "180bc5df-4977-496f-ee20-9e1c9924fe28"
      },
      "outputs": [],
      "source": [
        "# !pip install japanize-matplotlib\n",
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification                         \n",
        "import japanize_matplotlib #日本語表示対応\n",
        "\n",
        "\n",
        "# Notebook から src ディレクトリを追加\n",
        "sys.path.append(\"/home/keiseki/My_Python_project/src\")\n",
        "\n",
        "# これで src/preprocess/make_tag_features.py が import 可能\n",
        "from preprocess.make_tag_features import (\n",
        "    create_tag_features,\n",
        "    extract_unique_tags\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "csR9wtPUwBcd"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=pd.errors.PerformanceWarning\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 01.config読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_path = os.path.join( '../config/config.yaml')\n",
        "with open(conf_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定義した特徴量リストを読み込み\n",
        "feature_list = config['FEATURE']['FEATURE_LIST']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# カテゴリカルカラムのリストを定義\n",
        "categorical_cols = config['FEATURE']['CATEGORICAL_COLS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 02.データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLIBSLbkZpre",
        "outputId": "c396ab8d-e46f-4d3e-ef87-c4a3441a5e39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4466/1821816592.py:3: DtypeWarning: Columns (63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_train = pd.read_csv(train_path)\n"
          ]
        }
      ],
      "source": [
        "# ドライブ内のファイルパスを指定\n",
        "train_path = '../20.Data/train.csv'\n",
        "df_train = pd.read_csv(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4466/1294476357.py:3: DtypeWarning: Columns (46,55,56,63,146) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_test = pd.read_csv(test_path)\n"
          ]
        }
      ],
      "source": [
        "# testデータの読み込み\n",
        "test_path = '../20.Data/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "df_test[\"renovation_date\"] = pd.to_datetime(df_test[\"renovation_date\"])\n",
        "df_test[\"renovation_date\"] = df_test[\"renovation_date\"].astype(\"int64\") // 10**9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 03.前処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# df_trainのカテゴリカルカラムを'category'型に変換\n",
        "for col in categorical_cols:\n",
        "    if col in df_train.columns:\n",
        "        df_train[col] = df_train[col].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_testのカテゴリカルカラムを'category'型に変換\n",
        "for col in categorical_cols:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 極端に高い売買価格はクリッピング\n",
        "lower = df_train[\"money_room\"].quantile(0.01)\n",
        "upper = df_train[\"money_room\"].quantile(0.99)\n",
        "\n",
        "df_train[\"money_room\"] = df_train[\"money_room\"].clip(lower, upper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train[\"land_youto\"] = df_train[\"land_youto\"].where(\n",
        "    df_train[\"land_youto\"].isin([8, 14]),\n",
        "    np.nan\n",
        ").astype(\"category\")\n",
        "\n",
        "df_test[\"land_youto\"] = df_test[\"land_youto\"].where(\n",
        "    df_test[\"land_youto\"].isin([8, 14]),\n",
        "    np.nan\n",
        ").astype(\"category\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train[\"building_type\"] = (\n",
        "    df_train[\"building_type\"]\n",
        "    .where(df_train[\"building_type\"].isin([1, 3]), np.nan)\n",
        ").astype(\"category\")\n",
        "\n",
        "df_test[\"building_type\"] = (\n",
        "    df_test[\"building_type\"]\n",
        "    .where(df_test[\"building_type\"].isin([1, 3]), np.nan)\n",
        ").astype(\"category\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
            "/home/keiseki/My_Python_project/venv/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
          ]
        }
      ],
      "source": [
        "# 欠損値はカラムの型に応じて補完\n",
        "for col in df_train.columns:\n",
        "    if col == \"money_room\": # 目的変数はこの時点では補完しない\n",
        "        continue\n",
        "\n",
        "    # if col in categorical_cols: # 明示的に定義されたカテゴリカルカラム\n",
        "    #     # LightGBMが0をカテゴリとして扱えるため、0で補完\n",
        "    #     df_train[col] = df_train[col].fillna(0)\n",
        "    elif df_train[col].dtype in ['int64', 'float64']: # 数値カラム\n",
        "        # 数値カラムは訓練データの中央値で補完\n",
        "        median_val = df_train[col].median()\n",
        "        df_train[col] = df_train[col].fillna(median_val)\n",
        "        df_test[col] = df_test[col].fillna(median_val)\n",
        "    # else:\n",
        "        # # その他の型（objectなど）は、とりあえず0で補完（必要に応じて調整）\n",
        "        # df_train[col] = df_train[col].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # room_count\n",
        "# # unit_area\n",
        "df_train = df_train[(df_train[\"unit_area\"]>12.5) & (df_train[\"unit_area\"]<300)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 日付関係のデータは経過日数を特徴量とする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 'target_ym'をdatetime型に変換 (月の最初の日と仮定)\n",
        "df_train['target_date'] = pd.to_datetime(df_train['target_ym'].astype(str) + '01', format='%Y%m%d')\n",
        "df_test['target_date'] = pd.to_datetime(df_test['target_ym'].astype(str) + '01', format='%Y%m%d')\n",
        "\n",
        "# 'building_create_date'をdatetime型に変換\n",
        "df_train['building_create_date'] = pd.to_datetime(df_train['building_create_date'])\n",
        "df_test['building_create_date'] = pd.to_datetime(df_test['building_create_date'])\n",
        "# 築年数を計算 (年単位)\n",
        "df_train['building_age'] = (df_train['target_date'] - df_train['building_create_date']).dt.days // 365\n",
        "df_test['building_age'] = (df_test['target_date'] - df_test['building_create_date']).dt.days // 365\n",
        "\n",
        "# 'renovation_date'がUNIXタイムスタンプになっているため、再度datetimeに変換して経過年数を計算\n",
        "# 既に'renovation_date'はUNIXタイムスタンプに変換済みのため、元の日付情報に戻すか、元のカラムを使用する\n",
        "# ここでは、元のカラムが保持されていると仮定し、新しいカラムとして計算\n",
        "# 注: もしdf_train['renovation_date']がUNIXタイムスタンプのみになっている場合、この処理は調整が必要です。\n",
        "# 既存のrenovation_date（UNIXタイムスタンプ）を無視し、元の文字列カラムが存在しないため、新たに変換する\n",
        "# もし元の文字列カラムが失われている場合は、UNIXタイムスタンプをdatetimeに変換する\n",
        "# 現状のNotebookの処理から判断すると、renovation_dateはUNIXタイムスタンプなので、それを基に経過年数を計算します。\n",
        "\n",
        "# UNIXタイムスタンプからdatetimeへの変換\n",
        "df_train['renovation_datetime'] = pd.to_datetime(df_train['renovation_date'], errors='coerce')\n",
        "df_test['renovation_datetime'] = pd.to_datetime(df_test['renovation_date'], errors='coerce')\n",
        "\n",
        "# リノベーションからの経過年数を計算 (年単位)\n",
        "# リノベーション日がない場合はNaNとなり、NaNとtarget_dateの差もNaNになるため、後でfillnaで処理\n",
        "df_train['years_since_renovation'] = (df_train['target_date'] - df_train['renovation_datetime']).dt.days // 365\n",
        "df_test['years_since_renovation'] = (df_test['target_date'] - df_test['renovation_datetime']).dt.days // 365\n",
        "# 欠損値の補完\n",
        "# building_ageとyears_since_renovationの負の値（未来の日付）やNaNを処理\n",
        "# 例: 負の値やNaNを0で補完する\n",
        "df_train['building_age'] = df_train['building_age'].apply(lambda x: max(0, x) if pd.notna(x) else 0)\n",
        "df_test['building_age'] = df_test['building_age'].apply(lambda x: max(0, x) if pd.notna(x) else 0)\n",
        "\n",
        "df_train['years_since_renovation'] = df_train['years_since_renovation'].apply(lambda x: max(0, x) if pd.notna(x) else 0)\n",
        "df_test['years_since_renovation'] = df_test['years_since_renovation'].apply(lambda x: max(0, x) if pd.notna(x) else 0)\n",
        "# 新しい特徴量をfeature_listに追加\n",
        "new_features = ['building_age', 'years_since_renovation']\n",
        "feature_list.extend(new_features)\n",
        "\n",
        "# feature_listから'target_date', 'building_create_date', 'renovation_datetime'を削除 (直接特徴量として使わないため)\n",
        "# (元のbuilding_create_dateとrenovation_dateはUNIX timestampとして残しておく)\n",
        "feature_list = [f for f in feature_list if f not in ['target_date', 'building_create_date', 'renovation_date', 'renovation_datetime']]\n",
        "\n",
        "# 確認\n",
        "# print(df_train[feature_list].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 04.特徴量生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# addr1_1 と addr2_1をあわせた特徴量を作成\n",
        "df_train['addr1+2'] = df_train['addr1_1'].astype(str) + '_' + df_train['addr1_2'].astype(str)\n",
        "df_test['addr1+2'] = df_test['addr1_1'].astype(str) + '_' + df_test['addr1_2'].astype(str)\n",
        "feature_list.append('addr1+2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m all_unique_tags_list = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(all_unique_tags))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# create_tag_features 関数を df_train と df_test に適用\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df_train, new_tag_features = \u001b[43mcreate_tag_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_unique_tags_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df_test, _ = create_tag_features(df_test.copy(), all_unique_tags_list)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 既存の feature_list に new_tag_features を追加\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/src/preprocess/make_tag_features.py:30\u001b[39m, in \u001b[36mcreate_tag_features\u001b[39m\u001b[34m(df, unique_tags)\u001b[39m\n\u001b[32m     28\u001b[39m     col_name = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# 新しい二値カラムを作成。'statuses' が NaN の場合は fillna('') でエラー回避\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     df[col_name] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstatuses\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     new_tag_features_local.append(col_name)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df, new_tag_features_local\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/venv/lib/python3.11/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/venv/lib/python3.11/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/venv/lib/python3.11/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/venv/lib/python3.11/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/My_Python_project/src/preprocess/make_tag_features.py:30\u001b[39m, in \u001b[36mcreate_tag_features.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     28\u001b[39m     col_name = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# 新しい二値カラムを作成。'statuses' が NaN の場合は fillna('') でエラー回避\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     df[col_name] = df[\u001b[33m'\u001b[39m\u001b[33mstatuses\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m x.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     31\u001b[39m     new_tag_features_local.append(col_name)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df, new_tag_features_local\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# タグIDの分割により特徴量を追加\n",
        "\n",
        "# all_unique_tags という空の set を初期化\n",
        "all_unique_tags = set()\n",
        "# df_train の 'statuses' カラムに対して extract_unique_tags を呼び出し、得られたユニークタグを追加\n",
        "all_unique_tags.update(extract_unique_tags(df_train, 'statuses'))\n",
        "# df_test の 'statuses' カラムに対して extract_unique_tags を呼び出し、得られたユニークタグを追加\n",
        "all_unique_tags.update(extract_unique_tags(df_test, 'statuses'))\n",
        "# all_unique_tags をソートしてリストに変換し、all_unique_tags_list に格納\n",
        "all_unique_tags_list = sorted(list(all_unique_tags))\n",
        "\n",
        "# create_tag_features 関数を df_train と df_test に適用\n",
        "df_train, new_tag_features = create_tag_features(df_train.copy(), all_unique_tags_list)\n",
        "df_test, _ = create_tag_features(df_test.copy(), all_unique_tags_list)\n",
        "# 既存の feature_list に new_tag_features を追加\n",
        "feature_list.extend(new_tag_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 極端な値はクリッピング\n",
        "for col in feature_list:\n",
        "    # 数値型でなければスキップ\n",
        "    if not pd.api.types.is_numeric_dtype(df_train[col]):\n",
        "        continue\n",
        "\n",
        "    # 全部NaNの列はスキップ\n",
        "    if df_train[col].notna().sum() == 0:\n",
        "        continue\n",
        "\n",
        "    # 1% / 99% パーセンタイル\n",
        "    lower = df_train[col].quantile(0.01)\n",
        "    upper = df_train[col].quantile(0.99)\n",
        "\n",
        "    # パーセンタイルが計算できない場合はスキップ\n",
        "    if pd.isna(lower) or pd.isna(upper):\n",
        "        continue\n",
        "\n",
        "    # クリッピング\n",
        "    df_train[col] = df_train[col].clip(lower, upper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBM 用に使用するカテゴリ特徴量のリストを作成\n",
        "categorical_features = [\n",
        "    col for col in categorical_cols\n",
        "    if col in feature_list\n",
        "]\n",
        "\n",
        "feature_list = feature_list.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['addr1+2'] = df_train['addr1+2'].astype('category')\n",
        "df_test['addr1+2']  = df_test['addr1+2'].astype('category')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "＿前処理後のDataFrameを出力保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 前処理後のDataFrameをpklファイルで出力保存\n",
        "\n",
        "df_train.to_pickle('../20.Data/processed_train.pkl')\n",
        "df_test.to_pickle('../20.Data/processed_test.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
