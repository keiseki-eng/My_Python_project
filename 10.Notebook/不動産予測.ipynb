{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX0ZdLopCj-f"
      },
      "source": [
        "★実行環境の選択"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mwpl2bQsv9Gp"
      },
      "outputs": [],
      "source": [
        "# VSCodeの場合\n",
        "# edi_flg = 1\n",
        "# Googlre Colabの場合\n",
        "edi_flg = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drmdF2ct3EBt",
        "outputId": "fad5e8b2-66df-4feb-d199-a5bd22fa4761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'My_Python_project'\n",
            "/content\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "if edi_flg == 0:\n",
        "# # GoogleColabにGitHubリポジトリをクローンする用\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  !git clone https://github.com/keiseki-eng/My_Python_project\n",
        "  %cd My_Python_project\n",
        "  !git pull origin main\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zq_NLJ4i2H_f"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A8CzKrBbb7O",
        "outputId": "cf2c4706-e2c0-485f-d4ac-c01b3ab5e637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting japanize-matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from japanize-matplotlib) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->japanize-matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.17.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120257 sha256=9c88cdd9b170df326243a8a7355538d1dcd88af743b06b540c15c19656c383ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/f7/9b/418f19a7b9340fc16e071e89efc379aca68d40238b258df53d\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n"
          ]
        }
      ],
      "source": [
        "if edi_flg == 0:\n",
        "    !pip install japanize-matplotlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "import japanize_matplotlib #日本語表示対応\n",
        "\n",
        "\n",
        "# Notebook から src ディレクトリを追加\n",
        "# sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
        "sys.path.append(\"/home/keiseki/My_Python_project/src\")\n",
        "\n",
        "# これで src/preprocess/make_tag_features.py が import 可能\n",
        "# from preprocess.make_tag_features import create_tag_features, extract_unique_tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31-po6qhAZLi",
        "outputId": "32639317-0c4a-4dfc-e72b-d75d3988b54e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "csR9wtPUwBcd"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=pd.errors.PerformanceWarning\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vel6-57c2H_i"
      },
      "source": [
        "## 01.config読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jOVigtnz2H_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "41f2eb5a-78ed-408d-d2cc-b1f47b6d3d62"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'My_Python_project/config/config.yaml'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1518629124.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0medi_flg\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mconf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"My_Python_project/config/config.yaml\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'My_Python_project/config/config.yaml'"
          ]
        }
      ],
      "source": [
        "# VSCode用\n",
        "if edi_flg==1:\n",
        "  conf_path = os.path.join( '../config/config.yaml')\n",
        "  with open(conf_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# GoogleColab用\n",
        "elif edi_flg==0:\n",
        "  conf_path = \"My_Python_project/config/config.yaml\"\n",
        "  with open(conf_path, \"r\") as f:\n",
        "    config = yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugpvxdsV2H_k"
      },
      "outputs": [],
      "source": [
        "# 定義した特徴量リストを読み込み\n",
        "feature_list = config['FEATURE']['FEATURE_LIST']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH-U-6i52H_k"
      },
      "outputs": [],
      "source": [
        "# カテゴリカルカラムのリストを定義\n",
        "categorical_cols = config['FEATURE']['CATEGORICAL_COLS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDwS_bGw2H_k"
      },
      "source": [
        "## 02.データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLIBSLbkZpre"
      },
      "outputs": [],
      "source": [
        "# VSCode用\n",
        "if edi_flg==1:\n",
        "# ドライブ内のファイルパスを指定\n",
        "    train_path = '../20.Data/processed_train.pkl'\n",
        "    df_train = pd.read_pickle(train_path)\n",
        "\n",
        "# GoogleColab用\n",
        "elif edi_flg==0:\n",
        "    # GoogleDriveをマウントしてファイル読み込み準備\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # ドライブ内のファイルパスを指定\n",
        "    train_path = '/content/drive/MyDrive/Colab Notebooks/不動産予測/processed_train.pkl'\n",
        "    df_train = pd.read_pickle(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfjIljDC2H_l"
      },
      "outputs": [],
      "source": [
        "# testデータの読み込み\n",
        "# VSCode用\n",
        "if edi_flg==1:\n",
        "    test_path = '../20.Data/processed_test.pkl'\n",
        "    df_test = pd.read_pickle(test_path)\n",
        "\n",
        "# GoogleColab用\n",
        "elif edi_flg==0:\n",
        "    # ドライブ内のファイルパスを指定\n",
        "    test_path = '/content/drive/MyDrive/Colab Notebooks/不動産予測/processed_test.pkl'\n",
        "    df_test = pd.read_pickle(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNkth9VW2H_n"
      },
      "source": [
        "## 05.train/valid 分割　＆　target加工"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDYt7poo2H_n"
      },
      "outputs": [],
      "source": [
        "# X_all, X_train, X_validの再構築\n",
        "X_all = df_train[feature_list]\n",
        "y_all = df_train[\"money_room\"]\n",
        "\n",
        "# log変換前の元価格を保存（後段の重み付け用）\n",
        "y_price_raw = df_train.loc[X_all.index, \"money_room\"]\n",
        "\n",
        "# unit_areaも対数変換\n",
        "X_all[\"unit_area\"] = np.log1p(X_all[\"unit_area\"])\n",
        "\n",
        "# 目的変数が右に裾野が広いので対数変換\n",
        "y_all = np.log1p(y_all)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5lPFsjA2H_o"
      },
      "source": [
        "## 06.sample_weight適用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzGe7M7I2H_o"
      },
      "outputs": [],
      "source": [
        "# 元スケールの価格\n",
        "y_price = y_all\n",
        "\n",
        "\n",
        "# train / valid に合わせる\n",
        "y_price_raw_train = y_price_raw.loc[X_train.index]\n",
        "\n",
        "# 低価格ほど重く（価格の逆数）\n",
        "sample_weight = 1 / np.log1p(np.maximum(y_price_raw_train, 1_000_000)* np.where(y_price_raw_train < 13_000_000, 2.0, 1.0) )\n",
        "\n",
        "# 正規化\n",
        "sample_weight = sample_weight / sample_weight.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbb7AzF2H_o"
      },
      "source": [
        "## 07.モデル学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9UzfPSES7je"
      },
      "outputs": [],
      "source": [
        "# カスタム評価関数（eval_metric形式）\n",
        "def mape_eval(preds, train_data):\n",
        "    y_true = np.expm1(train_data.get_label())\n",
        "    y_pred = np.expm1(preds)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-7))) * 100\n",
        "    return 'mape', mape, False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UthK6de1T6Ty"
      },
      "outputs": [],
      "source": [
        "# LightGBM のパラメータ設定\n",
        "params = config['MODEL_PARAMS']\n",
        "\n",
        "# LightGBM のデータセットを作成\n",
        "lgb_train = lgb.Dataset(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    weight=sample_weight.loc[X_train.index],\n",
        "    categorical_feature=categorical_cols\n",
        ")\n",
        "\n",
        "lgb_test = lgb.Dataset(\n",
        "    X_valid,\n",
        "    y_valid,\n",
        "    reference=lgb_train,\n",
        "    categorical_feature=categorical_cols\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V4dTzGRyA2XQ"
      },
      "outputs": [],
      "source": [
        "# モデルの学習\n",
        "model = lgb.train(params,\n",
        "                  lgb_train,\n",
        "                  valid_sets=[lgb_train, lgb_test],\n",
        "                  feval=mape_eval,  # ← カスタム評価関数を指定\n",
        "                  callbacks=[lgb.early_stopping(stopping_rounds=1000, verbose=False)\n",
        "                  ]) #early_stoppingあり\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ_AzEqc2H_p"
      },
      "source": [
        "## 08.評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ8MsZmS2H_p"
      },
      "outputs": [],
      "source": [
        "# テストデータで予測\n",
        "y_pred = model.predict(X_valid , num_iteration=model.best_iteration)\n",
        "\n",
        "# 対数変換を戻す\n",
        "y_pred = np.expm1(y_pred)\n",
        "y_valid = np.expm1(y_valid)\n",
        "\n",
        "# ★小細工:予測値が低価格帯であれば、予測値を1.5倍にする\n",
        "# y_pred = np.where(y_pred < 6000000, y_pred * 1.5, y_pred)\n",
        "# y_valid = np.where(y_valid < 6000000, y_valid * 1.5, y_valid)\n",
        "\n",
        "\n",
        "yp = pd.DataFrame(y_pred,columns=[\"%\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 特徴量の重要度\n",
        "print(\"特徴量の重要度\")\n",
        "lgb.plot_importance(model, figsize=(8,4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR1rdmTd2H_p"
      },
      "source": [
        "## 09.可視化（importance SHAP）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C5HVNvdJA7rn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import lightgbm as lgb\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # パラメータの探索範囲を指定\n",
        "# param_grid = {\n",
        "#     'num_leaves': [20, 30, 40],\n",
        "#     'learning_rate': [0.01, 0.1, 0.5],\n",
        "#     'max_depth': [5, 10]\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # グリッドサーチCV\n",
        "# gsearch = GridSearchCV(gbm, param_grid, cv=5) #cvは交差検証の回数\n",
        "\n",
        "# # データを学習\n",
        "# gsearch.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)])\n",
        "\n",
        "\n",
        "\n",
        "# # 最適なパラメータとスコアを表示\n",
        "# print('Best parameters found by grid search are:', gsearch.best_params_)\n",
        "# print('Best score:', gsearch.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqnAa0aHUkSF"
      },
      "outputs": [],
      "source": [
        "# # パラメータの辞書を結合\n",
        "# best_params = {**params, **gsearch.best_params_}\n",
        "\n",
        "# # 最適パラメータでモデルを再学習\n",
        "# model = lgb.LGBMClassifier(**best_params)\n",
        "# model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mtosh8APQ1hX"
      },
      "outputs": [],
      "source": [
        "#SHAP値の取得\n",
        "explainer = shap.TreeExplainer(model=model)#SHAP値を取得するためのモデル作成\n",
        "shap_values = explainer.shap_values(X=X_valid)#説明変数それぞれの値のSHAP値を取得する\n",
        "\n",
        "# print(shap_values)\n",
        "# print(shap_values.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHCG_cntQ60c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 変数別の影響度の可視化\n",
        "shap.initjs()\n",
        "shap.summary_plot(shap_values, X_valid)\n",
        "\n",
        "# 0番目のデータポイントを再選択\n",
        "i = 0\n",
        "single_observation = X_valid.iloc[i:i+1,:]\n",
        "\n",
        "#print(single_observation)\n",
        "\n",
        "\n",
        "# Explainerを使って説明を再計算\n",
        "single_shap_values = explainer(single_observation)\n",
        "\n",
        "# waterfallプロットの生成\n",
        "shap.waterfall_plot(single_shap_values[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQfAs_kZ2H_v"
      },
      "source": [
        "## 10.推論、提出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxCenyIHz0GT"
      },
      "source": [
        "## 提出用データの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G20PdnIGVCgo"
      },
      "outputs": [],
      "source": [
        "# 特徴量の選定\n",
        "df_test_p = df_test[feature_list].copy()\n",
        "df_test_p[\"unit_area\"] = np.log1p(df_test_p[\"unit_area\"])\n",
        "\n",
        "\n",
        "\n",
        "# 提出データに対する予測（確率値）\n",
        "y_scores_submit = model.predict(df_test_p)\n",
        "# # y_scores_binary_submit = np.where(y_scores_submit>0.5, 1, 0)\n",
        "\n",
        "\n",
        "y_scores_submit= np.expm1(y_scores_submit)\n",
        "\n",
        "# ★小細工:予測値が低価格帯であれば、予測値を1.5倍にする\n",
        "# y_scores_submit = np.where(y_scores_submit < 6000000, y_scores_submit * 1.5, y_scores_submit)\n",
        "\n",
        "\n",
        "print(y_scores_submit)\n",
        "\n",
        "# y_scores_survive_submit = y_scores_submit[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lWNqV26CjYJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#提出用csvの作成\n",
        "df_scores_submit = pd.DataFrame(y_scores_submit)\n",
        "\n",
        "# df_submit = pd.concat([df_test[\"id\"], df_scores_submit], axis=1)\n",
        "# df_scores_submit.index = df_scores_submit.index + 1\n",
        "df_scores_submit.to_csv(\"submit.csv\", index=True, header=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAODvXF1D6XY"
      },
      "outputs": [],
      "source": [
        "# テストデータに対する予測（確率値）？？？？？？？？？？？？？？？？？？？？？？？・\n",
        "y_scores = model.predict(X_valid)\n",
        "# y_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZUHToQRPbBJ"
      },
      "source": [
        "## 誤差要因分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE3uPKSQPdVh"
      },
      "outputs": [],
      "source": [
        "# valid予測\n",
        "y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
        "# 対数変換を戻す\n",
        "y_pred_valid = np.expm1(y_pred_valid)\n",
        "# ★小細工:予測値が低価格帯であれば、予測値を1.5倍にする\n",
        "# y_pred_valid = np.where(y_pred_valid < 6000000, y_pred_valid * 1.5, y_pred_valid)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_eval = X_valid.copy()\n",
        "df_eval[\"y_true\"] = y_valid\n",
        "df_eval[\"y_pred\"] = y_pred_valid\n",
        "\n",
        "# APE計算（0割防止）\n",
        "df_eval[\"ape\"] = np.abs(df_eval[\"y_true\"] - df_eval[\"y_pred\"]) / np.maximum(df_eval[\"y_true\"], 1e-7)\n",
        "\n",
        "# 上位ワースト確認\n",
        "# df_eval.sort_values(\"ape\", ascending=False).head(20)\n",
        "df_eval[\"スコア差分\"] = df_eval[\"y_true\"] - df_eval[\"y_pred\"]\n",
        "df_eval[\"スコア差分\"].plot.hist(bins=50, figsize=(10,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVqE_gmXPgoo"
      },
      "outputs": [],
      "source": [
        "# 価格帯ビン作成\n",
        "df_eval[\"price_bin\"] = pd.qcut(df_eval[\"y_true\"], q=5)\n",
        "\n",
        "# 価格帯別MAPE\n",
        "mape_by_bin = df_eval.groupby(\"price_bin\")[\"ape\"].mean() * 100\n",
        "print(\"価格帯別のMAPE\\n\", mape_by_bin)\n",
        "print()\n",
        "print(\"全データのMAPE\", df_eval[\"ape\"].mean())\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPfb_aJJPmdK"
      },
      "outputs": [],
      "source": [
        "def compare_distribution(col):\n",
        "    return pd.DataFrame({\n",
        "        \"train\": df_train[col].describe(),\n",
        "        \"valid\": X_valid[col].describe()\n",
        "    })\n",
        "\n",
        "# compare_distribution(\"money_rimawari_now\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65k3FdkrVQVN"
      },
      "outputs": [],
      "source": [
        "# APEが大きい上位10%\n",
        "threshold = df_eval[\"ape\"].quantile(0.9)\n",
        "bad_samples = df_eval[df_eval[\"ape\"] >= threshold]\n",
        "\n",
        "# SHAP値抽出\n",
        "shap_values_valid = explainer.shap_values(X_valid)\n",
        "shap_df = pd.DataFrame(\n",
        "    shap_values_valid,\n",
        "    columns=X_valid.columns,\n",
        "    index=X_valid.index\n",
        ")\n",
        "\n",
        "\n",
        "# 悪いサンプルのSHAP平均\n",
        "shap_df.loc[bad_samples.index].abs().mean().sort_values(ascending=False).head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GcuSM9FVYZK"
      },
      "outputs": [],
      "source": [
        "# shap.force_plot(base_value=explainer.expected_value, shap_values=shap_values, features=X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUrvXmwxm9Qw"
      },
      "outputs": [],
      "source": [
        "def calc_mape(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-7))) * 100\n",
        "\n",
        "\n",
        "# valid 予測\n",
        "y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
        "# 対数変換を戻す\n",
        "y_pred_valid = np.expm1(y_pred_valid)\n",
        "# ★小細工:予測値が低価格帯であれば、予測値を1.5倍にする\n",
        "# y_pred_valid = np.where(y_pred_valid < 6000000, y_pred_valid * 1.5, y_pred_valid)\n",
        "\n",
        "# MAPE 出力\n",
        "valid_mape = calc_mape(y_valid, y_pred_valid)\n",
        "print(f\"VALID MAPE: {valid_mape:.4f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eicRmSRU2H_x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 対数変換を戻した y_pred_valid と y_valid はすでに存在すると仮定\n",
        "\n",
        "# X_valid[\"unite_area\"] = np.expm1(X_valid[\"unit_area\"])\n",
        "\n",
        "df_eval = X_valid.copy()\n",
        "df_eval[\"unit_area\"] = np.expm1(df_eval[\"unit_area\"])\n",
        "df_eval[\"y_true\"] = y_valid\n",
        "df_eval[\"y_pred\"] = y_pred_valid\n",
        "df_eval[\"ape\"] = np.abs(df_eval[\"y_true\"] - df_eval[\"y_pred\"]) / np.maximum(df_eval[\"y_true\"], 1e-7)\n",
        "\n",
        "# 上位10%の誤差サンプル抽出\n",
        "threshold = df_eval[\"ape\"].quantile(0.9)\n",
        "bad_samples = df_eval[df_eval[\"ape\"] >= threshold]\n",
        "\n",
        "# 調査対象の特徴量リスト\n",
        "check_features = [\n",
        "    \"unit_area\",\n",
        "    \"post1\",\n",
        "    \"floor_plan_code\",\n",
        "    \"walk_distance1\",\n",
        "    \"walk_distance2\",\n",
        "]\n",
        "\n",
        "# タグ系カラムを抽出（feature_list に基づく）\n",
        "tag_features = [col for col in feature_list if col.startswith(\"tag_\")]\n",
        "check_features.extend(tag_features)\n",
        "\n",
        "# 1. 数値特徴量の誤差 vs 値域の関係\n",
        "num_features = [\"unit_area\", \"walk_distance1\", \"walk_distance2\"]\n",
        "for col in num_features:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.scatterplot(data=df_eval, x=col, y=\"ape\", alpha=0.3)\n",
        "    sns.scatterplot(data=bad_samples, x=col, y=\"ape\", color=\"red\", alpha=0.5)\n",
        "    plt.title(f\"{col} と予測誤差(APE)の関係\")\n",
        "    plt.ylabel(\"APE\")\n",
        "    plt.xlabel(col)\n",
        "    plt.show()\n",
        "\n",
        "# 2. カテゴリ特徴量の誤差分布（箱ひげ図）\n",
        "cat_features = [\"post1\", \"floor_plan_code\"]\n",
        "for col in cat_features:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.boxplot(x=col, y=\"ape\", data=df_eval)\n",
        "    plt.title(f\"{col} ごとの予測誤差(APE)分布\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# 3. タグ系特徴量の影響（悪いサンプルと全体比較）\n",
        "for col in tag_features:\n",
        "    if col not in df_eval.columns:\n",
        "        continue\n",
        "    mean_all = df_eval[col].mean()\n",
        "    mean_bad = bad_samples[col].mean()\n",
        "    print(f\"{col}: 全体平均={mean_all:.3f}, 誤差上位10%平均={mean_bad:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3nVh5UZ2H_y"
      },
      "outputs": [],
      "source": [
        "df_eval[\"unit_area\"] = np.expm1(df_eval[\"unit_area\"])\n",
        "X_valid[\"unit_area\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}